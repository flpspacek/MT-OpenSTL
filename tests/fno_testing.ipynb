{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spacefi1/MT/MT-OpenSTL/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "mt_path = os.path.abspath('/home/spacefi1/MT/MT-OpenSTL')\n",
    "if mt_path not in sys.path:\n",
    "    sys.path.append(mt_path)\n",
    "\n",
    "from math import floor\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from openstl.models.fno_model import FNO_Model\n",
    "torch.manual_seed(1035)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from icecream import install\n",
    "install()\n",
    "#\n",
    "#ic.configureOutput(includeContext=True)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        self.n = n  # Total number of samples\n",
    "        self.data = torch.rand(n, 1, 8)  # Random data with shape (n_samples, channel=1, first_dimension=8)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The input and target are the same (identity function)\n",
    "        sample = self.data[idx]\n",
    "        return sample, sample  # Return input and target as identical\n",
    "    \n",
    "\n",
    "class DoublingDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): Number of samples in the dataset.\n",
    "            a = torch.tensor([[1,2,5],\n",
    "                        [3,4,5]])\n",
    "            b = torch.tensor([[2, 2]])\n",
    "            torch.einsum('ij,ki->ij', a, b)\n",
    "        \"\"\"\n",
    "        self.n = n  # Total number of \n",
    "        self.m = 8\n",
    "        self.data = torch.ones(n, 1, self.m)\n",
    "        mask = torch.arange(self.m) % 2 == 1\n",
    "        self.data[:, :, mask] = self.data[:, :, mask] / 2\n",
    "\n",
    "        self.labels = torch.cat((self.data, self.data), axis=-1)\n",
    "\n",
    "        self.salt = torch.rand(n)[None, None, :]\n",
    "\n",
    "        self.data = torch.einsum('ijk,lmi->ijk', self.data, self.salt)\n",
    "        self.labels = torch.einsum('ijk,lmi->ijk', self.labels, self.salt)\n",
    "        #self.data = []\n",
    "        #for _ in range(10):\n",
    "        #    new_data = torch.randn(n // 10, 1, round(torch.FloatTensor(1).uniform_(4, 16)[0].item()))\n",
    "        #    ic(new_data.shape)\n",
    "        #    self.data.append(new_data)\n",
    "                    \n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The input and target are the same (identity function)\n",
    "        \n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label  # Return input and target as identical\n",
    "    \n",
    "class WavesDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.h, self.w = 8, 8  # Total number of samples\n",
    "        self.data = torch.ones(n, 1, self.h, self.w)\n",
    "        mask = torch.arange(self.w) % 2 == 1\n",
    "        self.data[:, :, :, mask] = self.data[:, :, :, mask] / 2\n",
    "\n",
    "        #self.labels = torch.ones(n, 1, self.h, self.w)\n",
    "        #mask = torch.arange(self.h) % 2 == 1\n",
    "        #self.labels[:, :, mask, :] = self.labels[:, :, mask, :] / 2\n",
    "\n",
    "        self.salt = torch.rand(n)[None, None, None, :]\n",
    "\n",
    "        self.data = torch.einsum('ijkl,mnoi->ijkl', self.data, self.salt)\n",
    "        self.coeff = torch.ones(n)[None, None, None, :] * 2\n",
    "        self.labels = torch.einsum('ijkl,mnoi->ijkl', self.data, self.coeff)\n",
    "        #self.labels = torch.einsum('ijkl,mnoi->ijkl', self.labels, self.salt)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The input and target are the same (identity function)\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label  # Return input and target as identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 53441\n"
     ]
    }
   ],
   "source": [
    "in_channels = 1\n",
    "out_channels = 1\n",
    "hidden_channels = 64\n",
    "#shape = (8,)\n",
    "n_modes = 4\n",
    "epochs = 41\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "lr = 1e-4\n",
    "freq_print = 10\n",
    "\n",
    "fno = FNO_Model('skip', n_modes, in_channels, out_channels, hidden_channels, ndim=2)\n",
    "fno.cuda()\n",
    "print(f'Model params: {sum(p.numel() for p in fno.parameters() if p.requires_grad)}')\n",
    "\n",
    "batch = 32\n",
    "train_size = 10_000\n",
    "test_size = 200\n",
    "train_set = WavesDataset(train_size)\n",
    "test_set = WavesDataset(test_size)\n",
    "#train_set = IdentityDataset(train_size)\n",
    "#test_set = IdentityDataset(test_size)\n",
    "train_loader = DataLoader(train_set, batch_size=batch, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136],\n",
       "        [0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136, 0.4273, 0.2136]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = next(iter(train_loader))\n",
    "a[0][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273],\n",
       "        [0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273, 0.8545, 0.4273]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Epoch: 0  ######### Train Loss: 0.003915699932436109  ######### Relative L2 Test Norm: 0.06071610748767853\n",
      "######### Epoch: 10  ######### Train Loss: 2.9324348713544168e-08  ######### Relative L2 Test Norm: 0.0033604430407285692\n",
      "######### Epoch: 20  ######### Train Loss: 5.217863565611936e-08  ######### Relative L2 Test Norm: 0.004157565571367741\n",
      "######### Epoch: 30  ######### Train Loss: 1.0452491428658561e-07  ######### Relative L2 Test Norm: 0.0014203966781497002\n",
      "######### Epoch: 40  ######### Train Loss: 1.5715464336274463e-08  ######### Relative L2 Test Norm: 0.005597985610365868\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(fno.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_mse = 0.0\n",
    "    for step, (input, target) in enumerate(train_loader):\n",
    "       input, target = input.cuda(), target.cuda()\n",
    "       optimizer.zero_grad()\n",
    "       #ic(target.shape[2:])\n",
    "       pred = fno(input, target.shape[2:])\n",
    "       loss = loss_func(pred, target)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       train_mse += loss.item()\n",
    "    train_mse /= len(train_set)\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input, target) in enumerate(test_loader):\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "            pred = fno(input, target.shape[2:])\n",
    "            #ic(pred)\n",
    "            #ic(pred.shape)\n",
    "            loss = (torch.mean((pred - target) ** 2) / torch.mean(target ** 2)) ** 0.5 * 100\n",
    "            test_relative_l2 += loss.item()\n",
    "        test_relative_l2 /= len(test_set)\n",
    "    \n",
    "    if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse, \" ######### Relative L2 Test Norm:\", test_relative_l2)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.0023, 1.9893, 1.9707,  ..., 1.0319, 1.0136, 1.0011],\n",
       "          [2.0023, 1.9893, 1.9707,  ..., 1.0319, 1.0136, 1.0011],\n",
       "          [2.0023, 1.9893, 1.9707,  ..., 1.0319, 1.0136, 1.0011],\n",
       "          ...,\n",
       "          [2.0023, 1.9893, 1.9707,  ..., 1.0319, 1.0136, 1.0011],\n",
       "          [2.0023, 1.9893, 1.9707,  ..., 1.0319, 1.0136, 1.0011],\n",
       "          [2.0023, 1.9893, 1.9707,  ..., 1.0319, 1.0136, 1.0011]]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, w = 8, 8  # Total number of samples\n",
    "x = torch.ones(1, 1, h, w)\n",
    "mask = torch.arange(w) % 2 == 1\n",
    "x[:, :, :, mask] = x[:, :, :, mask] / 2\n",
    "x = x.cuda()\n",
    "#x = x[None, None, :].cuda()\n",
    "out = fno(x, (64,256))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out.detach().cpu()[0,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [8, 8] and output size of (10,). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfno\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m out\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/openstl/models/fno_model.py:87\u001b[0m, in \u001b[0;36mFNO_Model.forward\u001b[0;34m(self, x, output_shape)\u001b[0m\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlifting(x)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m---> 87\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfourier_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shapes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m#ic(x.shape)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(x)\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/openstl/modules/fno_modules.py:188\u001b[0m, in \u001b[0;36mFNOBlock.forward\u001b[0;34m(self, x, idx, output_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, idx: \u001b[38;5;28mint\u001b[39m, output_shape: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# Skip connection with optional super-resolution\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     x_fno_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_connection(x)\n\u001b[0;32m--> 188\u001b[0m     x_fno_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspec_conv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_fno_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# Spectral convolution\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     x_fno \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec_conv(x, output_shape)\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/openstl/modules/fno_modules.py:94\u001b[0m, in \u001b[0;36mSpectralConv.transform\u001b[0;34m(self, x, output_shape)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_shape \u001b[38;5;241m==\u001b[39m output_shape:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/openstl/modules/fno_modules.py:65\u001b[0m, in \u001b[0;36mSpectralConv._resample\u001b[0;34m(x, res_scale, axis, output_shape)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39minterpolate(x, size\u001b[38;5;241m=\u001b[39moutput_shape[\u001b[38;5;241m0\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axis) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbicubic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mrfftn(x\u001b[38;5;241m.\u001b[39mfloat(), norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, dim\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m     69\u001b[0m new_fft_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(output_shape)\n",
      "File \u001b[0;32m~/MT/MT-OpenSTL/.venv/lib/python3.10/site-packages/torch/nn/functional.py:4453\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   4451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   4452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m-> 4453\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4454\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput and output must have the same number of spatial dimensions, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4455\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput with spatial dimensions of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and output size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4456\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide input tensor in (N, C, d1, d2, ...,dK) format and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4457\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput size in (o1, o2, ...,oK) format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4458\u001b[0m         )\n\u001b[1;32m   4459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m   4460\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_integer(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m size):\n",
      "\u001b[0;31mValueError\u001b[0m: Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [8, 8] and output size of (10,). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format."
     ]
    }
   ],
   "source": [
    "out = fno(x, (24,))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out.detach().cpu()[0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
